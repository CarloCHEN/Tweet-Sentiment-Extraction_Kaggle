{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Phrase extraction of the test dataset.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO1fNEVL5J5U8d54dytSdq1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarloCHEN/Tweet-Sentiment-Extraction_Kaggle/blob/master/Phrase_extraction_of_the_test_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_tV5hzb7TJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the nltk tokenizer \n",
        "import os\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bF5aCXS94rb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "47f5fd2a-265a-4fbb-c9bc-a1effc035a7a"
      },
      "source": [
        "# install the BERT pretrained model if not done yet\n",
        "pip install pytorch_pretrained_bert"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 27.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.4)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.5.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.13.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.16.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.4->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.4->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.17.0,>=1.16.4->boto3->pytorch_pretrained_bert) (1.12.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmcTvniY95sF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ea23a84-c82c-45c5-a98f-75e49e48a08a"
      },
      "source": [
        "# import libraries and utils\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z1rfaxv-Yx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code to read csv file into Google Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4ooC6-2-bFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the dataset from the link\n",
        "link = 'https://drive.google.com/open?id=1O3hcurUk6i_21vEdlJht0KKCiCayL7Dh'\n",
        "fluff, id = link.split('=')\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('test.csv')  \n",
        "test = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2q2u8zt_EuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use CUDA is cuda is available\n",
        "# otherwise use cpu\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m5DTVodBDmg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce73afa8-9220-41df-dc81-6db5756409fe"
      },
      "source": [
        "# load the tokenizer from bert_base_uncased model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 900294.13B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxf0H5e9_E4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize models\n",
        "# each for different sentiment \n",
        "# number of labels is 2 (\"0\" for absent, \"1\" for present)\n",
        "model_positive = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "model_positive = model_positive.cuda()\n",
        "\n",
        "model_negative = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "model_negative = model_negative.cuda()\n",
        "\n",
        "model_neutral = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "model_neutral = model_neutral.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTCfDxiN_qg7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f184e410-7cec-4056-8805-364b6e8d3f90"
      },
      "source": [
        "# mount the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2epLvqD-ru_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "249dc221-14b9-4a44-af99-a93357ccf5b4"
      },
      "source": [
        "# re-load the pretrained model from the drive\n",
        "model_save_name = 'BERT_for_negative_extraction.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "model_negative.load_state_dict(torch.load(path))\n",
        "\n",
        "model_save_name = 'BERT_for_positive_extraction.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "model_positive.load_state_dict(torch.load(path))\n",
        "\n",
        "model_save_name = 'BERT_for_neutral_extraction.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "model_neutral.load_state_dict(torch.load(path))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PTyLvlC-tHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the keywordextract method \n",
        "def keywordextract(model, sentence):\n",
        "    predicted_phrase = []\n",
        "    extracted_phrase = \"\"\n",
        "    text = sentence\n",
        "    tkns = tokenizer.tokenize(text)\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tkns)\n",
        "    segments_ids = [0] * len(tkns)\n",
        "    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
        "    segments_tensors = torch.tensor([segments_ids]).to(device)\n",
        "    # print(tokens_tensor)\n",
        "    # print(segments_tensors)\n",
        "    model.eval()\n",
        "    prediction = []\n",
        "    logit = model(tokens_tensor, token_type_ids=None,\n",
        "                                  attention_mask=segments_tensors)\n",
        "    logit = logit.detach().cpu().numpy()\n",
        "    # print(logit)\n",
        "    prediction.extend([list(p) for p in np.argmax(logit, axis=2)])\n",
        "    for k, j in enumerate(prediction[0]):\n",
        "      if j == 1:\n",
        "          predicted_phrase.append(tokenizer.convert_ids_to_tokens(tokens_tensor[0].to('cpu').numpy())[k])\n",
        "    for element in predicted_phrase: \n",
        "      extracted_phrase += element\n",
        "      extracted_phrase += \" \"\n",
        "    return extracted_phrase"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQOaQYwMG0tk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract the key phrase that reflects the sentiment from the original tweet text\n",
        "# use different model for different sentiment\n",
        "# write extracted phrase to a new column \n",
        "test['extracted_phrase'] = \"\"\n",
        "for i in range(test.shape[0]):\n",
        "  if (test['sentiment'][i] == \"positive\"):\n",
        "    test['extracted_phrase'][i] = keywordextract(model_positive,test['text'][i])\n",
        "  if (test['sentiment'][i] == \"negative\"):\n",
        "    test['extracted_phrase'][i] = keywordextract(model_negative,test['text'][i])\n",
        "  if (test['sentiment'][i] == \"neutral\"):\n",
        "    test['extracted_phrase'][i] = keywordextract(model_neutral,test['text'][i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q6UNxMJHmdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the submission dataframe\n",
        "submission = test[['textID','extracted_phrase']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEFPELKbQCzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save submission csv file to google drive\n",
        "submission.to_csv('/content/gdrive/My Drive/submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPtSRyMdQMjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}