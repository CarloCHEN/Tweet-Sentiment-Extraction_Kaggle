{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Phrase extraction by considering sentiment (positive).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOzGjyce6a4xSyMzBMBGAKM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarloCHEN/Tweet-Sentiment-Extraction_Kaggle/blob/master/Phrase_extraction_by_considering_sentiment_(positive).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgbogrYkP5yJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya7sxZGpTQn3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "9b028fe9-df77-4e1c-9559-df2783809df0"
      },
      "source": [
        "pip install pytorch_pretrained_bert"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.38.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.12.39)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.21.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.39 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.15.39)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.4.5.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.16.0,>=1.15.39->boto3->pytorch_pretrained_bert) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge0tRAo2TSdH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78dc36b1-0e52-402f-c5c1-0c431df0ad84"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6oARMFwTxtf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZymCiN8_TzuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "link = 'https://drive.google.com/open?id=1P4z6napWZDIZS7hFhnAL3GUYnxpz1aPS'\n",
        "fluff, id = link.split('=')\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('train_1.csv')  \n",
        "train = pd.read_csv('train_1.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ikt1AvBT6xQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06kTFS00T8JO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGWGILeeUgND",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04a88ef8-11e5-45e1-b14c-a893b1831a38"
      },
      "source": [
        "device"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdgXxPTPGM3_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e8cd625f-5285-4167-92a4-68bcf5e97c76"
      },
      "source": [
        "train[train['sentiment_ENG'] == 'positive']['text']"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1            Oh! Good idea about putting them on ice cream\n",
              "4                   haha better drunken tweeting you mean?\n",
              "6        had an awsome salad! I recommend getting the S...\n",
              "7         fine! Going to do my big walk today 20 or so ...\n",
              "8              Thank a yoou  how are you? #TwitterTakeover\n",
              "                               ...                        \n",
              "27471                         Stress-free is the way to be\n",
              "27476    tried oprahs free unfried kfc and loved it  i ...\n",
              "27479    Havin a much better day today!! Finished the l...\n",
              "27483                   see u bye see u!  i love the hot30\n",
              "27484           ha ha, and what game is that? i like games\n",
              "Name: text, Length: 8582, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTU4mKAeWV8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = train[train['sentiment_ENG'] == 'positive']['text']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inYPFRN_eL7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGMu1HcweN_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be701e1c-7b5b-40fe-b406-d6bc5490a2d1"
      },
      "source": [
        "max_len = 0\n",
        "for i in range(len(tokenized_texts)):\n",
        "    if (len(tokenized_texts[i]) > max_len):\n",
        "        max_len = len(tokenized_texts[i])\n",
        "    \n",
        "max_len"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nr-3IEBeTii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "selected = train[train['sentiment_ENG'] == 'positive']['selected_text']\n",
        "selected_tokenized_texts = [tokenizer.tokenize(sent) for sent in selected]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1Z-dg1weZlC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12a09203-dd9a-4f63-90a6-646c77a3b3e2"
      },
      "source": [
        "selected_max_len = 0\n",
        "for i in range(len(selected_tokenized_texts)):\n",
        "    if (len(selected_tokenized_texts[i]) > selected_max_len):\n",
        "        selected_max_len = len(selected_tokenized_texts[i])\n",
        "    \n",
        "selected_max_len"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbmTae1PfQ9S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00f9a486-8b6d-4323-f501-5155e355ab2e"
      },
      "source": [
        "len(selected_tokenized_texts)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8582"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmxrjgtVfnr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.arange(len(selected_tokenized_texts) * max_len)\n",
        "x = x.reshape(len(selected_tokenized_texts), max_len)\n",
        "x = np.zeros_like(x)\n",
        "labels = x\n",
        "\n",
        "for i in range(len(selected_tokenized_texts)):\n",
        "  for selected_token in selected_tokenized_texts[i]:\n",
        "    for j in range(len(tokenized_texts[i])):\n",
        "      if (selected_token == tokenized_texts[i][j]):\n",
        "        labels[i][j] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zUwtJ_Hh5lQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=max_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "attention_masks = [[float(i>0) for i in ii] for ii in input_ids]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCAgU2kykU2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_inputs, val_inputs, tr_labels, val_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnLhPrEEkiT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_inputs = torch.tensor(tr_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "tr_labels = torch.tensor(tr_labels)\n",
        "val_labels = torch.tensor(val_labels)\n",
        "tr_masks = torch.tensor(tr_masks)\n",
        "val_masks = torch.tensor(val_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX4UVK5dkt1n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ab81751-0c71-44af-a741-0b69837966bf"
      },
      "source": [
        "tr_labels.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([7723, 65])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjwjClPKkwTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = TensorDataset(tr_inputs, tr_masks, tr_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=32)\n",
        "\n",
        "valid_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RkapXe0kyxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "model = model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne97PZ89k4KY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FULL_FINETUNING = True\n",
        "if FULL_FINETUNING:\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    param_optimizer = list(model.classifier.named_parameters()) \n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qY_EGveBk7fi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "b1cb41ec-7cfe-4743-d5d8-a758376a69a3"
      },
      "source": [
        "%pip install seqeval"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.6/dist-packages (0.0.12)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.3.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPyggaBHk8vM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from seqeval.metrics import f1_score\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyrSYA2Bk-gB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tags_vals = ['absent', 'present']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me7ZB6GVlHik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "3acb2193-cb6d-486d-a3a5-b92e65095e11"
      },
      "source": [
        "epochs = 4\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "    # TRAIN loop\n",
        "    model.train()\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # add batch to gpu\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        # forward pass\n",
        "        loss = model(b_input_ids, token_type_ids=None,\n",
        "                     attention_mask=b_input_mask, labels=b_labels)\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        # track train loss\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        model.zero_grad()\n",
        "    # print train loss per epoch\n",
        "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    # VALIDATION on validation set\n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    predictions , true_labels = [], []\n",
        "\n",
        "    for batch in valid_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
        "                                  attention_mask=b_input_mask, labels=b_labels)\n",
        "            logits = model(b_input_ids, token_type_ids=None,\n",
        "                           attention_mask=b_input_mask)\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "        true_labels.append(label_ids)\n",
        "        \n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        eval_loss += tmp_eval_loss.mean().item()\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        \n",
        "        nb_eval_examples += b_input_ids.size(0)\n",
        "        nb_eval_steps += 1\n",
        "    eval_loss = eval_loss/nb_eval_steps\n",
        "    print(\"Validation loss: {}\".format(eval_loss))\n",
        "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "    pred_tags = [tags_vals[p_i] for p in predictions for p_i in p]\n",
        "    valid_tags = [tags_vals[l_ii] for l in true_labels for l_i in l for l_ii in l_i]\n",
        "    print(\"F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.5284404891335275\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  25%|██▌       | 1/4 [01:11<03:35, 71.80s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.5082934907189122\n",
            "Validation Accuracy: 0.665347024374802\n",
            "F1-Score: 0.03217972070431086\n",
            "Train loss: 0.458782088411741\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|█████     | 2/4 [02:23<02:23, 71.79s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.5122592493339821\n",
            "Validation Accuracy: 0.7364006278358128\n",
            "F1-Score: 0.07719928186714542\n",
            "Train loss: 0.37840651776179796\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  75%|███████▌  | 3/4 [03:35<01:11, 71.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.5503147156150253\n",
            "Validation Accuracy: 0.7567109844887621\n",
            "F1-Score: 0.0819349962207105\n",
            "Train loss: 0.29246362538869713\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 4/4 [04:46<00:00, 71.73s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.6260149346457587\n",
            "Validation Accuracy: 0.7227940012662235\n",
            "F1-Score: 0.08345932869670396\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ng-KgEPlteKl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "632a083a-cf3b-4e9c-e329-bcdabec6c449"
      },
      "source": [
        "model.eval()\n",
        "predictions = []\n",
        "true_labels = []\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "for batch in valid_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
        "                              attention_mask=b_input_mask, labels=b_labels)\n",
        "        logits = model(b_input_ids, token_type_ids=None,\n",
        "                       attention_mask=b_input_mask)\n",
        "        \n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    true_labels.append(label_ids)\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "    eval_loss += tmp_eval_loss.mean().item()\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    nb_eval_examples += b_input_ids.size(0)\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "pred_tags = [[tags_vals[p_i] for p_i in p] for p in predictions]\n",
        "valid_tags = [[tags_vals[l_ii] for l_ii in l_i] for l in true_labels for l_i in l ]\n",
        "print(\"Validation loss: {}\".format(eval_loss/nb_eval_steps))\n",
        "print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.6260149346457587\n",
            "Validation Accuracy: 0.7227940012662235\n",
            "Validation F1-Score: 0.1377049180327869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYEoQpLDteUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def keywordextract(sentence):\n",
        "    predicted_phrase = []\n",
        "    text = sentence\n",
        "    tkns = tokenizer.tokenize(text)\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tkns)\n",
        "    segments_ids = [0] * len(tkns)\n",
        "    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
        "    segments_tensors = torch.tensor([segments_ids]).to(device)\n",
        "    # print(tokens_tensor)\n",
        "    # print(segments_tensors)\n",
        "    model.eval()\n",
        "    prediction = []\n",
        "    logit = model(tokens_tensor, token_type_ids=None,\n",
        "                                  attention_mask=segments_tensors)\n",
        "    logit = logit.detach().cpu().numpy()\n",
        "    # print(logit)\n",
        "    prediction.extend([list(p) for p in np.argmax(logit, axis=2)])\n",
        "\n",
        "    for k, j in enumerate(prediction[0]):\n",
        "        if j==1 or j==0:\n",
        "          pass\n",
        "            # print(tokenizer.convert_ids_to_tokens(tokens_tensor[0].to('cpu').numpy())[k], j)\n",
        "        if j == 1:\n",
        "          predicted_phrase.append(tokenizer.convert_ids_to_tokens(tokens_tensor[0].to('cpu').numpy())[k])\n",
        "    print(\"predicted phrase is: \")\n",
        "    for element in predicted_phrase:  \n",
        "      print(element, end =\" \")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaDISX9eI7Ai",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "cc7df9d2-704e-443b-eb1c-03a1a329c7f6"
      },
      "source": [
        "sentences"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1            Oh! Good idea about putting them on ice cream\n",
              "4                   haha better drunken tweeting you mean?\n",
              "6        had an awsome salad! I recommend getting the S...\n",
              "7         fine! Going to do my big walk today 20 or so ...\n",
              "8              Thank a yoou  how are you? #TwitterTakeover\n",
              "                               ...                        \n",
              "27471                         Stress-free is the way to be\n",
              "27476    tried oprahs free unfried kfc and loved it  i ...\n",
              "27479    Havin a much better day today!! Finished the l...\n",
              "27483                   see u bye see u!  i love the hot30\n",
              "27484           ha ha, and what game is that? i like games\n",
              "Name: text, Length: 8582, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsfCwG4Mtivw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "daf0753a-b1f0-40f1-9def-42fdbcc820ab"
      },
      "source": [
        "keywordextract(sentences[8])\n",
        "print(\" \")\n",
        "print(\"correct phrase is: \" + selected[8])\n",
        "print(\" \")\n",
        "keywordextract(sentences[27484])\n",
        "print(\" \")\n",
        "print(\"correct phrase is: \" + selected[27484])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted phrase is: \n",
            "thank  \n",
            "correct phrase is: Thank\n",
            " \n",
            "predicted phrase is: \n",
            "i like games  \n",
            "correct phrase is: ? i like\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvbZ39BJw5K6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "506ac8d5-0ed3-4148-afaf-e9dc8b6b4deb"
      },
      "source": [
        "# save model to google drive\n",
        "# first, mount the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHx3wXfvCHiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the model with the defined name\n",
        "model_save_name = 'BERT_for_positive_extraction.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FwTEv-67DqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# re-load the model from the drive\n",
        "# model_save_name = 'classifier.pt'\n",
        "# path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "# model.load_state_dict(torch.load(path))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}